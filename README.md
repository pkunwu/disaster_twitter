<h1>disaster twitter</h1>
This is a competition on <a href="https://www.kaggle.com/c/nlp-getting-started/overview">Kaggle</a>.<br>
For the data cleaning part, I followed this <a href="https://www.kaggle.com/gunesevitan/nlp-with-disaster-tweets-eda-cleaning-and-bert">post</a>.<br>
For the modeling part, I used spacy word2vector and svm. The accuracy of the model is around 81%.<br>
For the future directions, I plan to try GBTD and other methods.
